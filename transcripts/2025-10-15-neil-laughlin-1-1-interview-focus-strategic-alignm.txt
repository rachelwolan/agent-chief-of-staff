in a three-hour meeting where the product engineering teams all have someone who's assigned a job is to make sure that the updates are prepared for the broader audience. And you, is that your preference to not have a product leader? Oh gosh, no, absolutely not. So I'm Neil Laughlin, I lead. Hi. Infrastructure, reliability, resilience, back-end services, API contracts, or I'm not allowed to call it platform engineering at Audit Board because that's someone else's organizational term, but in the industry that's pretty much the standard term in 2025 for what my team does. Audit Board is pretty interesting because it's very front-end developer focused. It's the only company I've worked at that has had significantly more front-end engineers than back-end engineers. I have a lot of the back-end engineers in my organization. For most of the existence of Audit Board, there's been a suspicion around the P word, the platform word, and use of it, as well as a belief that, oh, those guys will take care of the infrastructure over there. Those are my guys, and women. It's an exciting product function to lead, but one of my major challenges, which I think relates to your role at Webflow, is getting the product side of the house actually interested in what we're doing on the infrastructure, back-end, and services side. So if I had my way, the product managers would be very interested in all the cool things we can tell them about all the data we have and the analytics that we're collecting on the performance and adoption of their features in production. So far, though, my enthusiasm has not transferred as well as I might wish over to them spending time with me. Got it. Well, then I will introduce myself as well. I'm Rachel. I run product design and insights, which is like data science, analytics engineering, BI, user research, and I've been at Webflow for two years now, almost two years, and then part of that spent almost four years at Dropbox, and then part of that I spent, let's see, as a developer for about five years, spent a decade at true startups, like kind of hyper-growth startups, and then moved into what I call teenage public companies when I started working for LiveRamp. I would call Dropbox in that kind of teenage category and Webflow's probably like pre-teen. I like that term. Yeah, like just to kind of give you, I always find that to be helpful. Your methodology of big versus small. It's not just big, it's maturity. I think maturity, especially in this discussion, is important. Definitely the index to share. I've spent probably the largest total number of years, definitely the largest total number of years of my professional experience at Microsoft, but generally working in companies that had been acquired by Microsoft, usually in the Valley, up until the last two, three or so years where I had an actual, true Microsoft job at Microsoft, and then I went to Medallia, which was a, I think a 600-person company when I got there. Many of the people there talked about how big the company was, and I just, I thought that was funny because I had come from, I think they were a 90,000-person company. So they had kind of grown up at Medallia. Yeah. So that whole what's big, what's small, what is challenging to get things done in versus easy, agile, nimble, what's a reasonable pace to expect with a particular volume of customer revenue, customer dependence on the services that we are providing, where we, as whatever company I'm at, has really been an interesting trend to travel through over the course of my career. Interesting. So maybe I would love to dive in a little bit with you on maybe a time when you had to translate company, product, or business strategy, let's say, into your multi-year platform roadmap. Sorry, maybe platform isn't the right word. Yeah, like platform is a fair word to use. Okay. I'm gonna start with the company map right now because I think it's really interesting to translate my experience into this fantastic keyword that they have. So when I started interviewing with Audit Board, it was not my first choice for a company to leave Salesforce to go to. But I asked a lot of questions around how long does it take you to do standard infrastructure activities coming from Salesforce where, I'm going to say things were slow, it would be quarters to build out a new region, weeks to onboard a new customer, a lot of ongoing activity around that. I said this since we were not very quick coming from Salesforce. And I really liked the answers that I was hearing as I was talking to the engineering SVP that was my hiring manager. Days, hours, minutes to get things done. But he had the impression that the tool that the infrastructure engineering team or DevOps team as it was called then owned, which was called Galaxy, still called Galaxy, was technical debt and that we were gonna swap it out for some other thing. It wasn't very good. So it was interesting for me to come from the big companies and the similarly sized companies and say, your answers are really good. If you can stand up a new instance for customers in under 30 minutes time, that's fantastic. Okay, the implementation on top of the new shell takes longer, that's normal. And that's not just an engineering problem. So a lot of what I've done in the platform side at Audit Board is go from this thing we have called Galaxy that started as a set of scripts for the infrastructure engineers to automate their boring routine tasks to actually being a platform that unlocks some real value for Audit Board on the business side. By making easy to produce duplicates of customer instances for debugging or support use cases or sandboxes and demoing new features. And then opening up the thinking from being, oh, this is just a tool for the DevOps crew to others, customer success agents that are working with Galaxy to do their jobs day to day. Sales engineering has their own environment and needs to manage the life cycle associated with using Galaxy to spin up these short life instances. We try a lot and et cetera, et cetera. Galaxy has really been an enormous multiplier for Audit Board. And a lot of what I've done is just say, no, it's good, you're doing good things. There's more work that needs to be done to meet the customer needs, internal customers and external customers along the way. But let's look at the part of the framework that are good, make sure that we're getting the full value out of those and then the places where there are rough edges or just gaps in the initial understanding of what the platform could do. Those need to be filled out. Got it. So it sounds like some of the work that you've done on the Galaxy V2, let's call it. V2, we're just, we're going. We're just going. Galaxy. It's hard to avoid the replatforming event in the space of the tools and platforms that are totally under my team's control. It doesn't mean we don't occasionally talk about replatforming or have replatforming projects. But I think one of the things that has really made Galaxy a success is that we've been able to incrementally deliver with both North Stars and some immediate business goals tied into it over the course of the last two, two and a half years. Maybe talk to me about the North Stars that you said. Yeah, so North Star on Galaxy. Making the platform usable by a variety of different internal users, not just the savvy infrastructure engineer, but the support personnel in the customer success organization, the sales organization. The call I had just before this was talking about enabling partners to be able to deliver managed services. And the conversation immediately turned to what would they need to use Galaxy? So that's a new persona that we had not previously, I had not previously discussed using Galaxy. And it led to maybe one of the requirements. Do they need Galaxy? Does that actually unlock value for them in this proposed new business offering? Can we avoid them needing to use Galaxy? Should we avoid them needing to use Galaxy? But it's essentially making sure that we can deliver audit board services to a variety of customers quickly with as delightful user experience as possible for something that is fundamentally built out of an internal system for automating common internal tasks. Got it. So how do you think about the roadmap for internal tasks when you maybe kind of have like different external parties, maybe some are external, some are, when I'm talking about internal, or when you're talking about internal, maybe can I clarify, are you talking about internal users like support and sales? Or are you talking about other developers that are building on your not platform? They're all customers. Okay. My perspective. So when I say internal users, it's really anyone in audit board that has a task they need to accomplish where the platform Galaxy is the right way for them to work more efficiently or be able to do work that normally they wouldn't be able to do at all. The different types of customers have different use cases and different needs. Assessing what they want against the priorities driven by engineering product and business leadership is always part of evaluating which way we want to go. But the North Star is really, Galaxy is the way a internal user at audit board understands and manages the product offering from an infrastructure perspective, software life cycle perspective that we're delivering to the customers, the end customers who are using the product. What benefit does the end customer get? If you're basically just trying to get everybody to build on Galaxy, but what's the key benefit? And maybe it's different for different customers. At Medallia, we talked about the benefits of containerization as moving from every customer's instance is hand built, like building boats by hand to having standard fleets. Galaxy is the way that right now, if you sell a customer a new instance, the customer actually gets that new instance. It's not a ticket. It's not a tech meeting to go to the data center and provision new hardware so that we can deliver the new customer the capacity to be able to meet their needs. Galaxy is the way you solve these common problems involved in service delivery to customers. And in the ideal world, as we add new products, the architecture gets more complex. It's still Galaxy at the heart of making it easy to go and say, okay, we have the new customer. They can go into the instance. They can see the reporting. It gets automatic version updates. The infrastructure capacity is managed. There's auto scaling so that they're using the service more. We ramp up, but if they're not using it, we ramp down and are cost-efficient for the business. So that's all in the North Star of what the product meeting the infrastructure needs to do as part of the Galaxy. Got it. So to paraphrase and tell me if I'm getting this wrong, you are effectively, for each customer, they get a container as their instance that is getting perfect. I'm sure there's an application that is living inside of that container and has a set of, there's value prop, but just in terms of like trying to understand, and your goal is guaranteeing uptime, your goal is guaranteeing freshness of data, consistency. Consistency, version of code is managed. Infrastructure is reproducible, ephemeral. We are applying security patches in a predictable way. There's no issues at the network layer. We're managing the lower level of infrastructure, the database, storage, networking, and other dependencies in a way that is consistent, well-understood, reproducible. Got it. Thank you. Has there been a situation where the product team wanted to build something sooner than a capability? that Galaxy offered? Like, how did you kind of navigate? Back to the North Star and why it would be good to have an official product manager on this. So, we don't really have a paved path for new service introductions to Audit Board at present. This is a problem I've worked at at Salesforce and Medallia in the past, as well as earlier in my career as well. It should be possible for a developer who says, okay, we need this new service. The monkey bagel service is critical to our business success. How do we get the monkey bagel service up and running at Audit Board? Because Audit Board has used the monolith pattern for most of its last 10 years, the way you would historically introduce that new service is by going and adding more code into the monolith. With 10 years, it's a pretty chunky monolith. Nothing like what Salesforce had done, which is just a phenomenal journey through what you can do in a monolith if you just keep doubling down on the monolithic pattern of over time. But if we want to build a new service off monolith for any of a variety of reasons at present at Audit Board, I need to say, hey, engineer in my team, can you go and sit with the reporting team, the monkey bagel team, to help them figure out how they can manage their new service alongside the monolith and ensure that all of the predictable setup, configuration, management, observability, et cetera, is attached to this new thing they would like to build alongside the core product. Got it. So right now, this sounds like there's a new service that happens kind of manually where you have to go and spend time. This book is the word I used in a deck that I was updating earlier today because we haven't made the investments in building a platform for new service deployment. It's essentially working with a skilled craftsman to create something alongside the more automated elements managed by Galaxy today. And we could do better. It would probably unlock additional velocity if we gave developers more tools to work in more of what the industry calls microservices. I think both monolith and microservices have their strengths and limitations. I started in service-oriented back when I got going on this whole new service. I really like that service-oriented make the decisions for the problems yourself. Thank you. I was trying to shield you from that. No worries. I'm the one recovering from COVID, so I'm glad- No. Oh no, I'm sorry. Thanks for getting on a call with me. It was not too bad, fortunately. That's good. I'm glad to be with you today. Yeah. Okay, so new service sounds like still there's a lot of manual effort, bespokeness, to use your words. Yeah, so the way we solve that problem today is essentially through an embedded engineering model. There are enough engineers in my organization that understand how the product as exists today and the infrastructure come together that we can tap one and say, please go work with this new team that needs to introduce some functionality, help them build it out in a way that is consistent with the standards we've created within Audit Board to date. In practice, we're generally faster than product development. There are a few cases where we're trying to buy and integrate something that is largely its own SaaS and we just want to craft the integration between them where I think the product engineering teams can move at a velocity that can put pressure on infrastructure engineering. But honestly, in some of those cases, we don't need to integrate. If we're working with Salesforce and we're building a pull from Salesforce, that's not creating Salesforce as part of our actual core architecture. This is just an integration. So I want to go back to one of the things you said earlier about your organization having most of the back-end engineers. This is kind of the first time you'd worked at a company that had more of a front-end application strategy. Can you talk to me a little bit about what that transition has been like for you? Obviously, we are a no-code product that I would say the balance of our engineers are on the front end. I think we can use more back-end engineers, but that's a different story. But how do you think about that? And then how do you think about, yeah, let's start with that. Time is finite and there were always areas where I didn't have to go dig deep into the problems because other people were working on them. An example is JavaScript library dependency hell is a problem that was always somebody else's problem to deal with. I thought, oh, I'm a back-end person. I'm never gonna have to go deep. But man, it was really hard over there. I'm glad there are people taking care of that. I've had to learn how to deal with that situation. I have both learned from the smart people on my team who understand it deeply, drawn on research from reading how other companies have solved this via the internet and connections on my network who I know have lived through these problems. I hope I'm also bringing a sense of humor and perspective to some of the problems that we face, which often feel like crises in the moment, but going and updating a dependency because a security vulnerability has been discovered is just the norm in 2025. So build an organization that has the signals for the work that needs to be done. Make sure I understand what the signals are in that space and then go and do the right thing drawing on the expertise that we have or can hire into the organization. I will say that to the starting question, since moving to enterprise software as a service, coming out of Microsoft into Medallia, I've been working on platforms, different use of the P word here, where the sales motion is you go to a potential customer and you say you're a business, so you have problems. And we have a platform solution that solves problems in the customer experience or customer relationship management or audit risk and compliance space. And then the implementations per customer are really shaped by that customer's business. What I've learned is that to be successful, I can't try to understand every possible customer use case for the product. It has to be reduced down to, do I have signals on it that's performant, scaled appropriately for the customer and not throwing exceptions, which would mean the customer's going to be unhappy about it. And then where necessary, I'll go deeper into the specific use case for our customers having problems with some feature of a board driven by the number of entities they're trying to collect compliance reports on or some other real customer specific issue. Finding the patterns of those, though where multiple customers are running into the same product related challenge based on some commonality in their implementation, that's interesting. That's a place where I think my systems experience has really served me well across a variety of different product use cases. How do you think about codifying your systems experience and maybe augmenting with AI to build that out as, you know, like what you're describing sounds like something where you should be able to have a system that is actually looking for those patterns. So last week I was in the UK at ObservabilityCon where I was on the Grafana Labs customer advisory board because one of the things that is most interesting to me is observability, understanding the behavior of the systems that we're running both from a reliability perspective and also from a usage perspective. The holy grail throughout my career has been understanding the customer experiences fundamentally about abstracting these numbers so we're collecting using metrics, logs, traces, all of these observability signals. If there's a thing that AI should be good at it's extracting patterns of behavior and saying, hey human, you should be aware that every other instance is not having out of memory errors but these particular ones are having out of memory errors where this customer is using the product in different ways as demonstrated by the logging. Through my career to date, and I think still today, anomalies are relatively easy actionable anomalies that a human has to go do something about have been harder to extract from the relatively easily discoverable massive list of anomalies. My fingers are crossed that right now the tools provided by companies like Gravana are good enough that we can actually get meaningful human informed anomalies out of what we're calling AI and then we can make better business decisions based on that. I do think the value that I and any human brings to interacting with AI is judgment. AI doesn't really have an understanding of the world, it doesn't have an understanding of how to sell better to customers. Humans still have to make decisions but the AI can service data that would be very difficult for a human to extract. A very basic model of it there is, it takes me a long time to look at 20 different dashboards in Gravana when I'm trying to understand why a customer is escalating that they're having a performance issue. The AI should be able to quickly recognize, oh, there's more traffic and it's showing up in one place but not the counter that you're looking at. Hey, you probably want to improve your visualization so that you're aware that the external API is being added, not just interactive users. Interesting. I'm gonna leave a few minutes at the end, I promise, for you to ask me questions. I have one more question. I think that product and platform often have different clock speeds. Infrastructure too. Sure, infrastructure as well, for sure. Maybe I'm coarsely lopping them together for the sake of this but I'm trying to get more philosophical. Optimizing for speed of features versus stability scale. How do you think about build, and it sounds like you've had to do this a lot yourself in your current role but how do you think about building durable alignment? Yeah. The companies that I've worked at have had different cultures around what success actually is. And the realization that I worked originally in Microsoft, an engineering-led company that would go do engineering stuff just because it would, there were a lot of really bright engineers who had great ideas and they would go build stuff without a product mindset and then nobody would buy it. Like that ultimately was one of the areas where a pattern of disappointment after a large amount of effort and emotional investment led me to ask the question, are there other ways to do this? I like this space that I've been in over the last, say three companies, where Medallia, Salesforce, and Audit Board are all solutions or sales-led companies powered by technology and engineering that are really looking to make sure that we make our customers successful. From my perspective, the product side is trying to figure out how to solve problems for customers. And the platform and infrastructure function are trying to make sure that we're doing that efficiently and that what we told a customer would work for them actually works. I like a daily stream of new challenges coming in. That's why I'm happier on the infrastructure and platform side, whereas on the product side, there are people who I think are just more patient at working through the research and the customer conversations and longer-term roadmap planning. I just love the fast pace of the, okay, what can I do today to make the customer experience better? And it could come from observability, it could come from talking to customer success partners, it could be coming from other engineering or product teams, it could be coming from outside. But the fact that the role I've been in for the majority of my career gives me so many sources of information to draw on and figure out, okay, what can I do today to solve problems for customers and make this company a success? It's really inspiring. Cool. Um... When you have encountered tension, how do you think about debugging that? So first, most technology problems in my career have actually turned out to really be people problems. And then when there are people problems, what are the incentives? The chief architect likes to bring in new technology at Auditor. She's an architect, she can still do things. But when she tries to get engagement from the product engineering teams, often it doesn't happen at the pace she's hoping for. She's super excited about this new thing she's built out. I almost never say super excited, I'm using it in a story, so I shouldn't do that. She's excited about this new innovation she's discovered and is providing for them to use. Their incentives though are ship features and drive additional annual recurring revenue over the course of the next year. There's commitments made by the product leaders around how much revenue will come from these capabilities. So in my mind, if I can get the conversation together there so that the incentives that the architect has and the incentives that the product engineering team has are the same or at least complementary, then I've done some good people management work during the course of the day. Where there's a major mismatch in incentives and motivations that is not as easily solved as everybody wins, then I go in and I learn more about what's driving the difference of opinions and try to figure out how best to create alignment or at least a common understanding of differences of opinion. Got it. Super helpful. Well, I wanna give you time to ask me questions. You said two years at Webflow, is that right? Okay. So I guess coming out of my own strategic planning over the last month and a half, how does strategic planning happen at Webflow? Yeah, so I would say we are doing it quite differently now than even when I started. So when I kind of walked in, we had fresh strategic plan that I had not put into place but I was like, okay, I'm gonna take this ball, I'm gonna run with it and... You never did a plan? Yeah, but it was a plan where I was like, this more or less makes sense for where we're at right now and we're going multi-product, we're trying to move up market. These are the like very clear set of things you would go do. And so a lot of things happened in the last two years and I would say we had to basically continue on that trajectory, which I still think was the right trajectory, moving from website platform to an experience platform. I still think it will pay a lot of dividends but we've also had to really adjust around a couple of different areas. Obviously, I think that the... Like if you think about what we do, we help you build your website, we help you manage the content on your website and then we help you optimize that website. So the natural questions that one would ask is, well, what's gonna happen with websites? Optimizes the performance and scale elements. Right, so analytics, personalization, basically what happens after you've launched your website and are trying to actually understand how people behave on your website as well as trying to test out different H1 tags, for example. But a couple of things have happened that have really disrupted us. One is CodeGen, I think has just taken off and become very accessible to the less technical user. I think we oftentimes appeal to the 99.9% of people who could not code and now prompt to prototype is pretty rampant. So that was one place where we didn't... That basically kind of came out in December of last year, I think Lovable was launched. I just wrote Lovable down before you said that. Yeah, and I think that it... And then I think that what's happened with just anthropics models and codecs and I mean, they've all really made... Prompting to get to, let's say, 70%, 80%. Usually not 90 or 100% for like a brand, but getting to a pretty good place has become very, very accessible for anybody who can write English. So I think that's been an interesting area for us to explore. We launched a product at our conference that is like directly in that space. And so that's kind of one. I think two, we were really just very focused on our websites up until this year. And we're able to move into apps. And again, if you like... One of the things that you said at the top that I think is interesting is like, you want your technology... That you want basically what you're building as a platform to be something that product cares about. And I can tell you that that is one of the products that we sell. Like hosting is a product. So if hosting does not work, our customers are really unhappy. It is one of the core value propositions that we sell to our customers. But I do think that we've also been able to take a lot of what we did to build our own web apps and use that to launch web apps, to launch our cloud. And we've also been able to take advantage of partners who already use like Cloudflare to be able to do that. Do it fairly quickly. We launched our cloud. We had a couple of people working on it and launched it in like three months. So I think that that's where we've seen a lot of benefit in both the technology partners we've chosen, as well as the infrastructure we've built for ourselves. And then I think the third thing that has really happened over the last, year, let's say, so it's September, October. So as of like September of last year is really what's happening with answer engine optimization. And just in general, there's a wide range of things that are happening to every single marketing team ranging from, and every company is slightly different in terms of like how they want to respond to answer engines. You could be on one end of the spectrum, Reddit selling your data, or you could be super disrupted like G2 and HubSpot because they were like very kind of like hedged on SEO. Or you could be very, very interested in getting your traffic, getting your content crawled because you're just sort of like, hey, this is like a new place for growth. And like, I as like a startup actually want to participate and it not just be dominated by companies that have like played the SEO game for 20 years. So there's a wide range of different outcomes. And again, that is also very tied to your infrastructure. What bots are you letting crawl? When do you let them crawl? When do you deny them? What rules have you set up? What content have you created? Is your content fresh enough? Is your content accurate compared to what your competitors have on the market because you might have like a head-to-head? Can you complete an outcome? And I think that's kind of where this ends up going because what you see start to happen is like, let's say AEO has eaten the top of funnel. And at least like part of it, most sites are probably down at least 15% from SEO and they're organic, probably closer to 25% and that's just gonna keep going and a lot of that is based on Google. But they're seeing very highly qualified traffic come from like ChachiBT and I think they will also see really highly qualified traffic come from Google. So like, yeah. Interesting thing that happened because it's essentially a redo of something that Microsoft was trying to do on that last project I did there and the AI technology was not, what we're now calling AI was not sufficient to accomplish the goals at that point. But I feel like it is really succeeding and disruptive at this point. It's kind of both. It's like sort of, the way I would describe it is, the disruption is actually happening mostly from Google in a lot of ways. And then I think there's like an augmentation to what people do with search. That then is also disruptive because you are pre-qualified by the time you like, hit the page of Audit Board or Webflow. And you have like a preconceived notion and then how long are you going to spend on the site? 30 seconds? Depends, like that's why we've, you'll kind of see our approach is bifurcated where we are trying to both create a platform that allows you to delight the human that does show up and so we've invested heavily in like animation, for example. And we also want you to be able to share your brand in a authentic way with the answer engine to be able to answer authentically on a very, very vast long tail of content. So it's kind of, and that requires schema generation and like using lms.txt appropriately and generating markdown. I mean like all kinds of things that you were not thinking about six months ago. Yeah, exactly. The outcome you're looking for. It's similar to one of the developer efficiency team challenges I have in my team right now. We have 10 years of old code written across JavaScript and TypeScript. The realization that rewriting the code to make it more easily understood by the AI dev tools was a high opener for me. Previously it was very hard to sell technet elimination to the engineering leadership as something that was necessary. But the fact that we can open up the content, the company be more productive and then the secondary effect of making the business more successful was really an interesting realization. You have a more direct approach where the changes of the behavior of the customers as AI is inserted in the mix is forcing you to change how you present content. I had thought about that before this conversation. Yeah, and it's just a cat and mouse game, right? Where you don't always know what a search engine's going to do or what a answer engine's gonna do. So I'll give you examples that happened in the last two weeks. Google shut down, they changed their URL such that LLMs could no longer guess the URL to go to page 99, right, of a search result. And it makes sense, that was part of their IP. But then what's interesting is obviously they've had to probably build out their own search engines that then go and crawl. And then they are also, like when GPT-5 came out, it completely changed the inference behavior of the model. Because previously, and the inference behavior of every single model is totally different. And as well as the training behavior in terms of like what the sites see. And so you might decide you only want inference bots to show up and to be allowed in, but you don't want training bots. Or you might only want training bots. But they're not like being like, hey, I'm an inference bot. They've never worn trustworthy name tags. They've never worn trustworthy name tags. And so it's just like a very, and then as a result of the changes that happened with GPT-5, basically they changed how they cited sources. And then it changed, it completely changed like the signup behavior on a bunch of sites. So it's like this, you know, you sort of have to be constantly adapting is maybe how I would put it. Because the behavior of the model is changing so rapidly. You're looking at a change every two months. And so getting back to your original question about strategic planning, we had a plan. We had to throw away half the plan. Yeah, your multi-year roadmap question now sounds more like my lived experience of multi-year roadmaps, which is really multi-year. That's a- We've gone to, we have a vision of where we're going. Like we're gonna be an AI native DXP. Like I can, you know, we presented that to the board. People have a good idea of like what that looks like. However, I will tell you we do a six-week roadmap right now. Realistically, the planning horizon for Medallia and Audit Board has been about six months. We know what we're doing in the coming quarter and we have a good idea of what we're doing in the following quarter. And I have long taken the position that that's the right amount of planning to do given the rate at which our businesses have to change in that 600 to 1,200 person company. And we're probably on a six-week cadence right now. I mean, we've just wrapped, we've decided that, I mean, of course there are projects that are going to take months, right, or quarters. However, I'm like, I wanna be able to make that decision that we're gonna make a change in six weeks because that's- at which this particular segment is advancing. Makes sense for the circumstances you're in. The realization, one of the realizations I had in the conference last week was, this is like the web at the beginning and mobile. Yeah. In that it's coming for you, oh company, and you can't ignore it. It's not like cloud where you had the choice of whether you wanted to migrate your business to have somebody else provide servers to you or not. Yeah. So sitting this out and assuming that you will be able to run the same business you ran before. It is like the web except the adoption curve is seven times faster. So OpenAI went from zero users to 800 million users in about two years. That took, that's how long it took, 14 years in the internet. But obviously there's no infrastructure and so, and so I think that's the, like the infrastructure has already been laid down to make this possible. I know we're at. Yeah, sorry, I have a couple more minutes. Okay. Yeah. Let me know if you have a hard cut off. The enterprise call out was something that came up I think when I was talking with Lindo or, what does it mean to go enterprise as your focus in the digital experience platform? Sure. I think that's what DXP stands for. That is what it stands for. Sorry, I shouldn't use acronyms. No, it's good. I like it when I figure acronyms out. So I, you know, look, I think traditionally when you thought of Webflow, we were probably one of two things. We were a startup who wanted to go and have a website and publish their website and have CMS and have content and a blog and whatever. In the last, let's say, two years, three years, we've pretty rapidly moved up market. I would say more into mid-market, but we definitely have straight down the middle enterprise customers. Like we have Fortune 50 customers that have their main.com on Webflow. And then we have million dollar customers. So I think that there is like what, to me, what is a DXP is we help you build, manage, and optimize any kind of digital experience that you have, whether it's a mobile experience, whether it's a e-commerce site and that experience. We may not be the merchant of record. That's not what we're trying to be. That's Shopify, BigCommerce, whatever. But we will be the experience layer. And that requires a lot of custom development work right now if you want to. And you're usually using an agency. It's like very, very expensive. And so. Marketing, the core competency of Webflow then. What's that? Digital marketing, the core competency. Yeah, marketing, that's our budget that we sell out of. So marketers, right now, I would say, if I kind of look at our customer base, it's probably a mix of 60, 70% B2B, 30, 40% B2C, some e-commerce like mixed into that B2C. But our e-commerce business is largely down market. We have probably about 350,000 customers. And we have a couple thousand customers that are in that upper segment. And it's really where all the growth is coming from our business, because that is where they still need a platform. And if you kind of think about what our platform is, you get to offload hosting to another company. And you get to call someone when there's a problem. And you don't rely on your own IT and your own developers. That is one of our core value propositions, hence why availability, reliability, super important. You, and security, of course. You have a system that developers, designers, and marketers can all use to produce on-brand beautiful experiences and content. And it's all like knitted together in a nice interoperable way. And that is really a collaboration platform at its core. So that is what you're buying from us. You're not buying a website. Like there are a bazillion platforms where you can buy a website. You're buying a collaboration platform, and a managed host. Yeah, my entry point for understanding Webflow is definitely website provider. So this has been very illuminating in understanding, A, how you're dealing with constant disruption, the world we live in in 2025. But also what it means to be going up market to be a provider for an enterprise scale customer. Awesome. Well, I do have to run. Thank you for your time today, Rachel. Really nice to meet you. Thanks so much for your time, Neil. All right, take care. Bye.